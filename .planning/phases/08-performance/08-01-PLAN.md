# Phase 08-01: Performance Optimization Analysis

**Status:** PLAN  
**Created:** 2026-02-04  
**Estimated Effort:** 3-5 days  

---

## Problem Statement

ShreeHR deployed on Vercel free tier feels slow. Users report noticeable delays when navigating the application, particularly on initial page loads and data-heavy pages like employee lists, dashboards, and payslips.

---

## Root Cause Analysis

### 1. Cold Starts (Primary Issue - HIGH IMPACT)

**Evidence:**
- Vercel free tier aggressively scales to zero
- First request after idle can take 3-10 seconds
- `@prisma/adapter-pg` with connection pooling adds ~500ms initial connection time
- External PostgreSQL database (likely Neon) adds network latency

**Impact:** Users experience 3-10 second waits on first visit or after ~15 minutes of inactivity.

### 2. No Data Caching (HIGH IMPACT)

**Evidence from code analysis:**
- Every API route hits database directly via Prisma
- Dashboard page makes 3 sequential `prisma.*.count()` calls
- Employee dashboard makes 3 separate queries (leave balances, last payslip, pending requests)
- Reference data (departments, designations, leave types) is fetched fresh every request

**Example - Dashboard page:**
```typescript
// src/app/dashboard/page.tsx - 3 uncached queries
const [employeeCount, departmentCount, documentCount] = await Promise.all([
  prisma.employee.count(),
  prisma.department.count(),
  prisma.document.count(),
]);
```

**Impact:** Each page load incurs 50-200ms database latency even when data hasn't changed.

### 3. External Database Latency (MEDIUM IMPACT)

**Evidence:**
- Database is external PostgreSQL (connection string-based)
- No edge caching or connection pooling at platform level
- Every request establishes new connection context

**Impact:** 30-100ms added latency per query depending on region.

### 4. No ISR/Static Generation (LOW IMPACT for this app)

**Evidence:**
- `next.config.ts` has no revalidate settings
- All pages are dynamic (require auth)
- No use of `unstable_cache` or `cache()` from React

**Impact:** Limited impact since most pages need authentication anyway.

---

## Data Caching Analysis

### Cache-Worthy Data Categories

| Category | Data | Change Frequency | TTL Recommendation | Users Affected |
|----------|------|------------------|-------------------|----------------|
| **Reference Data** | Departments, Designations, Leave Types, PT Slabs | Rarely (days/weeks) | 1 hour | All |
| **Dashboard Aggregates** | Total employee count, department count | Hourly | 5 minutes | All admins |
| **User Profile** | Employee personal data | Occasionally | 15 minutes (invalidate on update) | Per employee |
| **Session Context** | Current employee ID, role | Per session | Session-bound | Per user |
| **Statutory Data** | Deadlines, PT slabs | Daily | 30 minutes | Admins |

### Frequently-Hit Endpoints

1. **`/api/employees` (GET)** - List with pagination, includes joins
2. **`/api/attendance` (GET)** - Date-range queries, frequent access
3. **`/api/dashboard/statutory` (GET)** - 4+ queries for deadline data
4. **`/api/leave-balances/*`** - Per-employee, accessed often
5. **Dashboard pages** - Multiple count queries

---

## Solution Evaluation

### Option A: Upstash Redis (RECOMMENDED)

**What:** Serverless Redis with global edge replication, perfect for Vercel.

**Pros:**
- Free tier: 10,000 commands/day, 256MB storage
- Edge-replicated (low latency globally)
- Already using `ioredis` (just need to switch URL)
- Works with existing BullMQ setup (unified infrastructure)
- Simple key-value caching with TTL

**Cons:**
- External dependency
- Free tier limits (may need paid for production scale)

**Cost:** Free tier adequate for small team, $10/mo for pro.

**Implementation:**
```typescript
// Use existing connection.ts, add caching helpers
import { getRedisConnection } from '@/lib/queues/connection';

export async function cached<T>(
  key: string,
  ttlSeconds: number,
  fetcher: () => Promise<T>
): Promise<T> {
  const redis = getRedisConnection();
  const cached = await redis.get(key);
  if (cached) return JSON.parse(cached);
  
  const data = await fetcher();
  await redis.setex(key, ttlSeconds, JSON.stringify(data));
  return data;
}
```

### Option B: Vercel KV

**What:** Vercel's managed Redis (Upstash under the hood).

**Pros:**
- Native Vercel integration
- Same as Upstash technically

**Cons:**
- No free tier (starts at $0.20/100K requests)
- Vendor lock-in

**Verdict:** Skip. Just use Upstash directly for same functionality, better pricing.

### Option C: Next.js `unstable_cache` + React `cache`

**What:** Built-in Next.js caching without external dependencies.

**Pros:**
- Zero infrastructure - works with Vercel out of box
- Per-request deduplication with `cache()`
- Persistent caching with `unstable_cache()`
- No cold-start penalty (cache warms with function)

**Cons:**
- Per-instance cache (doesn't share across serverless invocations)
- Less control over invalidation
- Can't cache across API routes easily

**Implementation:**
```typescript
import { unstable_cache } from 'next/cache';
import { cache } from 'react';

// Within a request - deduplicates calls
export const getDepartments = cache(async () => {
  return prisma.department.findMany({ where: { is_active: true }});
});

// Across requests - persists for revalidate period
export const getCachedDepartments = unstable_cache(
  async () => prisma.department.findMany({ where: { is_active: true }}),
  ['departments'],
  { revalidate: 3600 } // 1 hour
);
```

### Option D: Hybrid Approach (BEST SOLUTION)

**What:** Use `unstable_cache` for most things, Upstash for invalidation-critical data.

**Why:**
1. `unstable_cache` handles 80% of cases (reference data, dashboard aggregates)
2. Upstash Redis for session-scoped data that needs explicit invalidation
3. Existing Redis setup can stay for BullMQ queues
4. Progressive - start with unstable_cache, add Redis only where needed

---

## Recommendation: Start with `unstable_cache`, Add Upstash Later

### Phase 1: No-Cost Quick Wins (Day 1-2)

Use Next.js built-in caching - no new infrastructure needed.

**Target:**
1. Reference data endpoints (departments, designations, leave types)
2. Dashboard aggregate counts
3. PT slab configuration

**Expected Impact:** 40-60% reduction in database queries.

### Phase 2: Upstash for User-Specific Data (Day 3-4)

Add Upstash free tier for:
1. Employee profile cache (invalidate on profile update)
2. Leave balance cache (invalidate on leave request approval)
3. Session context caching

**Expected Impact:** Additional 20-30% improvement for logged-in users.

### Phase 3: Cold Start Mitigation (Day 5, Optional)

Options:
1. **Vercel Cron ping** - Free tier allows 2 cron jobs, ping every 5 minutes
2. **Prisma Accelerate** - Connection pooling service ($20/mo)
3. **Upgrade to Pro** - Always-on functions ($20/mo)

For a small HR app, the cron ping is usually sufficient.

---

## Implementation Steps

### Step 1: Create Caching Utility

```typescript
// src/lib/cache.ts
import { unstable_cache } from 'next/cache';
import { prisma } from './db';

// Reference data - cache for 1 hour
export const getCachedDepartments = unstable_cache(
  () => prisma.department.findMany({ 
    where: { is_active: true },
    orderBy: { name: 'asc' }
  }),
  ['departments-active'],
  { revalidate: 3600, tags: ['departments'] }
);

export const getCachedDesignations = unstable_cache(
  () => prisma.designation.findMany({
    where: { is_active: true },
    orderBy: { title: 'asc' }
  }),
  ['designations-active'],
  { revalidate: 3600, tags: ['designations'] }
);

export const getCachedLeaveTypes = unstable_cache(
  () => prisma.leaveType.findMany({
    where: { is_active: true },
    orderBy: { name: 'asc' }
  }),
  ['leave-types-active'],
  { revalidate: 3600, tags: ['leave-types'] }
);

// Dashboard counts - cache for 5 minutes
export const getCachedDashboardCounts = unstable_cache(
  async () => {
    const [employees, departments, documents] = await Promise.all([
      prisma.employee.count({ where: { employment_status: 'ACTIVE' }}),
      prisma.department.count({ where: { is_active: true }}),
      prisma.document.count({ where: { is_deleted: false }}),
    ]);
    return { employees, departments, documents };
  },
  ['dashboard-counts'],
  { revalidate: 300, tags: ['dashboard'] }
);
```

### Step 2: Update Dashboard Page

```typescript
// src/app/dashboard/page.tsx
import { getCachedDashboardCounts } from '@/lib/cache';

export default async function DashboardPage() {
  const session = await auth();
  const counts = await getCachedDashboardCounts();
  // ... rest of component
}
```

### Step 3: Update API Routes to Use Cache

For employee list dropdown (departments/designations):
```typescript
// In forms that need department list
import { getCachedDepartments } from '@/lib/cache';

const departments = await getCachedDepartments();
```

### Step 4: Add Cache Invalidation

```typescript
// src/lib/cache.ts
import { revalidateTag } from 'next/cache';

export function invalidateDepartments() {
  revalidateTag('departments');
}

export function invalidateDashboard() {
  revalidateTag('dashboard');
}
```

Use in mutation endpoints:
```typescript
// POST /api/departments
await prisma.department.create({ ... });
invalidateDepartments();
invalidateDashboard();
```

### Step 5: (Optional) Add Upstash for User Data

```typescript
// src/lib/cache-redis.ts
import { getRedisConnection } from './queues/connection';

export async function cacheEmployeeProfile(employeeId: string) {
  const redis = getRedisConnection();
  const profile = await prisma.employee.findUnique({
    where: { id: employeeId },
    include: { department: true, designation: true }
  });
  await redis.setex(`employee:${employeeId}`, 900, JSON.stringify(profile));
  return profile;
}

export async function getCachedEmployeeProfile(employeeId: string) {
  const redis = getRedisConnection();
  const cached = await redis.get(`employee:${employeeId}`);
  if (cached) return JSON.parse(cached);
  return cacheEmployeeProfile(employeeId);
}

export async function invalidateEmployeeProfile(employeeId: string) {
  const redis = getRedisConnection();
  await redis.del(`employee:${employeeId}`);
}
```

---

## Success Criteria

| Metric | Current (Estimated) | Target |
|--------|---------------------|--------|
| Cold start time | 5-10s | 3-5s (with cron ping) |
| Dashboard load (warm) | 500-800ms | 150-300ms |
| Employee list load | 400-600ms | 200-350ms |
| Profile page load | 300-500ms | 100-200ms |
| Database queries per page | 3-5 | 1-2 (cache hits) |

---

## Estimated Effort

| Task | Time |
|------|------|
| Create caching utility (`src/lib/cache.ts`) | 2 hours |
| Update dashboard pages to use cache | 2 hours |
| Update reference data API routes | 3 hours |
| Add cache invalidation to mutations | 2 hours |
| Set up Upstash (if needed) | 1 hour |
| Testing and verification | 2 hours |
| **Total** | **12-16 hours (2-3 days)** |

---

## Risk Assessment

| Risk | Likelihood | Mitigation |
|------|------------|------------|
| Stale data shown to users | Medium | Short TTLs (5 min for counts), explicit invalidation on writes |
| Cache key collisions | Low | Use consistent naming: `{entity}:{id}:{context}` |
| Upstash free tier limits | Low | 10K commands/day is generous for small team |
| Memory pressure with large datasets | Low | Only cache aggregates and reference data, not full lists |

---

## Final Verdict

**Don't add Redis just for caching yet.** 

Start with `unstable_cache` from Next.js - it's free, requires no infrastructure, and will handle 80% of the performance issues. The app already has Redis configured for BullMQ job queues, so if user-specific caching becomes necessary later, Upstash can be added incrementally.

**Priority order:**
1. ✅ Cache reference data (departments, designations, leave types) - biggest bang for buck
2. ✅ Cache dashboard aggregates - most visible improvement
3. ⏳ Add Upstash only if user-specific invalidation becomes a pain point
4. ⏳ Cold start mitigation (cron ping) as final polish

The real bottleneck is likely cold starts + uncached database queries, not lack of Redis. Fix the easy stuff first.
