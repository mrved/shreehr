# Plan 07-03: Claude API Integration

## Objective
Replace Ollama with Claude API for better reasoning, faster responses, and production reliability.

## Context
@file:src/app/api/chat/route.ts
@file:package.json
@file:docs/research/AI-ASSISTANT-RESEARCH.md

## Tasks

### Task 1: Install Anthropic SDK
**Type:** auto

**Files:**
- `package.json` (modify)
- `.env.example` (modify)
- `.env` (modify locally)

**Action:**
```bash
pnpm add @anthropic-ai/sdk
```

Add to .env.example:
```
ANTHROPIC_API_KEY=sk-ant-...
AI_PROVIDER=claude  # or 'ollama' for local
```

**Verify:**
```bash
pnpm list @anthropic-ai/sdk
```

**Done:** Anthropic SDK installed, env vars documented

### Task 2: Create Claude Provider
**Type:** auto

**Files:**
- `src/lib/ai/claude-provider.ts` (create)
- `src/lib/ai/provider.ts` (create)

**Action:**
Create provider abstraction:

```typescript
// provider.ts
export interface AIProvider {
  chat(messages: Message[], tools: Tool[]): AsyncIterable<StreamChunk>;
}

export function getAIProvider(): AIProvider {
  const provider = process.env.AI_PROVIDER || 'ollama';
  if (provider === 'claude') return new ClaudeProvider();
  return new OllamaProvider();
}
```

```typescript
// claude-provider.ts
import Anthropic from '@anthropic-ai/sdk';

export class ClaudeProvider implements AIProvider {
  private client = new Anthropic();
  
  async *chat(messages, tools) {
    const stream = await this.client.messages.stream({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 4096,
      system: SYSTEM_PROMPT,
      messages: convertMessages(messages),
      tools: convertTools(tools),
    });
    
    for await (const event of stream) {
      yield convertStreamEvent(event);
    }
  }
}
```

**Verify:**
TypeScript compiles

**Done:** Claude provider created with streaming support

### Task 3: Update Chat Route
**Type:** auto

**Files:**
- `src/app/api/chat/route.ts` (modify)

**Action:**
Replace direct Ollama usage with provider abstraction:
- Use `getAIProvider()` to get configured provider
- Keep existing tool definitions
- Keep existing RBAC enforcement
- Add error handling for API failures

**Verify:**
```bash
# With AI_PROVIDER=claude
curl -X POST /api/chat -d '{"message": "What is my leave balance?"}'
```

**Done:** Chat route uses configurable AI provider

### Task 4: Add Vercel Environment Variable
**Type:** checkpoint:human-action

**Files:** None (Vercel dashboard)

**Action:**
Add to Vercel project settings:
- `ANTHROPIC_API_KEY` = (Ved's API key)
- `AI_PROVIDER` = `claude`

**Verify:**
Vercel deployment uses Claude

**Done:** Production configured for Claude

## Success Criteria
1. Claude API integrated with streaming
2. Provider abstraction allows switching Ollama/Claude
3. Existing tools work unchanged
4. Production deployed with Claude
