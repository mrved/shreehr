# Phase 10-01: AI Chat Fix Execution Plan

**Date:** 2026-02-04  
**Status:** Awaiting Approval  
**Estimated Effort:** 30 minutes

---

## Problem Statement

AI Chat is not working in production (Vercel). Need to identify and fix the root cause.

---

## Proposed Fixes

### Fix 1: Add Better Error Visibility (Required)

**File:** `src/lib/ai/model-client.ts`

**Change:** Add explicit error when Anthropic is configured but unavailable

```typescript
export async function getChatModel() {
  const provider = process.env.AI_PROVIDER?.toLowerCase() || 'ollama';
  
  if (provider === 'anthropic') {
    if (!process.env.ANTHROPIC_API_KEY) {
      throw new Error('AI_PROVIDER is "anthropic" but ANTHROPIC_API_KEY is not set');
    }
    if (!anthropicModule) {
      anthropicModule = await import('@ai-sdk/anthropic');
    }
    return anthropicModule.anthropic('claude-sonnet-4-20250514');
  }
  
  // Ollama fallback with warning
  if (process.env.NODE_ENV === 'production') {
    console.warn('[AI] Using Ollama in production - this will likely fail on serverless');
  }
  
  const ollama = createOllama({
    baseURL: process.env.OLLAMA_BASE_URL || 'http://localhost:11434/api',
  });
  
  return ollama(process.env.OLLAMA_MODEL || 'llama3.2:3b');
}
```

**Benefit:** Fails fast with clear error message instead of silently falling back.

---

### Fix 2: Add Provider Logging to Chat Route (Debug)

**File:** `src/app/api/chat/route.ts`

**Change:** Already has logging but make it more visible:

```typescript
// Existing line is good:
console.log(`[Chat] Using AI provider: ${providerInfo.provider}, model: ${providerInfo.model}`);

// Add to catch block:
} catch (error) {
  const providerInfo = getProviderInfo();
  console.error(`[Chat] Error with provider ${providerInfo.provider}:`, error);
  return Response.json(
    { 
      error: error instanceof Error ? error.message : 'Chat failed',
      provider: providerInfo.provider // Include in dev mode for debugging
    },
    { status: 500 }
  );
}
```

---

### Fix 3: Verify/Update Vercel Environment Variables (Manual)

**Required Variables on Vercel:**

| Variable | Required Value | Notes |
|----------|----------------|-------|
| `AI_PROVIDER` | `anthropic` | Must be lowercase |
| `ANTHROPIC_API_KEY` | `sk-ant-api03-...` | Valid Anthropic API key |

**How to verify:**
1. Go to Vercel Dashboard → shreehr project
2. Settings → Environment Variables
3. Check both variables exist and are correct
4. Ensure they're enabled for Production environment

---

## MCP Implementation Decision

### Recommendation: DO NOT IMPLEMENT MCP

**Reasons:**
1. ShreeHR is a single-purpose Next.js app
2. Only one AI interface exists (embedded chat)
3. Current tool architecture is clean and working
4. MCP adds complexity without benefit for this use case
5. Would require significant refactoring

**MCP would make sense if:**
- External apps need to access ShreeHR's AI tools
- You want Claude Desktop integration
- Building a mobile app with separate AI backend

**Decision:** Skip MCP for Phase 10. Revisit if multi-client need arises.

---

## Success Criteria

- [ ] Chat API returns responses when `AI_PROVIDER=anthropic` is set
- [ ] Clear error message if `ANTHROPIC_API_KEY` is missing
- [ ] Vercel function logs show correct provider being used
- [ ] End-to-end test: User asks "What's my leave balance?" → AI uses tool → Returns real data

---

## Testing Plan

### Local Test
```bash
# Build and run with production settings
pnpm build
AI_PROVIDER=anthropic ANTHROPIC_API_KEY=sk-ant-... pnpm start

# Test endpoint
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello"}]}'
```

### Production Test
1. Deploy to Vercel
2. Login as test user
3. Open AI Chat
4. Ask: "What's my leave balance?"
5. Verify tool is called and data is returned

---

## Files to Modify

| File | Change | Risk |
|------|--------|------|
| `src/lib/ai/model-client.ts` | Add explicit error + warning | Low |
| `src/app/api/chat/route.ts` | Enhance error logging | Low |
| Vercel Dashboard | Verify env vars | None |

---

## Rollback Plan

If fixes cause issues:
1. Revert `model-client.ts` to previous version
2. Error handling changes are additive, unlikely to break

---

## Approval Request

Ved, please review and approve:
- [ ] Fix 1: Fail-fast error handling
- [ ] Fix 2: Enhanced error logging  
- [ ] Fix 3: Verify Vercel env vars (manual step)
- [ ] Skip MCP implementation

Once approved, I'll execute the code changes.
