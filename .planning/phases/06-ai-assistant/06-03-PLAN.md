---
phase: 06-ai-assistant
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/qdrant/embeddings.ts
  - src/lib/qdrant/search.ts
  - src/lib/ai/tools/policy-search.ts
  - src/lib/queues/embedding.queue.ts
  - src/lib/queues/workers/embedding.worker.ts
autonomous: true

must_haves:
  truths:
    - "System can generate embeddings for text using Ollama"
    - "System can search policy documents by semantic similarity"
    - "RAG results are filtered by user role"
    - "Policy updates trigger background embedding jobs"
  artifacts:
    - path: "src/lib/qdrant/embeddings.ts"
      provides: "Embedding generation and document chunking"
      exports: ["generateEmbedding", "chunkDocument"]
    - path: "src/lib/qdrant/search.ts"
      provides: "Semantic search with role filtering"
      exports: ["searchPolicies"]
    - path: "src/lib/ai/tools/policy-search.ts"
      provides: "AI tool for policy search"
      exports: ["createPolicySearchTool"]
    - path: "src/lib/queues/embedding.queue.ts"
      provides: "BullMQ queue for embeddings"
      exports: ["embeddingQueue", "addEmbeddingJob"]
  key_links:
    - from: "src/lib/qdrant/embeddings.ts"
      to: "ollama"
      via: "embedding model"
      pattern: "ollama\\.embedding"
    - from: "src/lib/qdrant/search.ts"
      to: "qdrant"
      via: "vector search"
      pattern: "qdrant\\.search"
---

<objective>
Create RAG infrastructure for policy document search including embedding generation, semantic search with RBAC filtering, and background embedding job processing.

Purpose: Enable the AI assistant to answer policy questions by searching company documents with semantic similarity and role-based visibility.
Output: Complete RAG pipeline from document ingestion to search results for AI consumption.
</objective>

<execution_context>
@C:\Users\ved\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\ved\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ai-assistant/06-RESEARCH.md

@src/lib/queues/connection.ts
@src/lib/qdrant/client.ts
@src/lib/ai/ollama-client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create embedding generation and document chunking utilities</name>
  <files>
    src/lib/qdrant/embeddings.ts
  </files>
  <action>
Create `src/lib/qdrant/embeddings.ts` for embedding generation and document chunking.

1. Import embedding utilities:
```typescript
import { embed } from 'ai';
import { embeddingModel } from '@/lib/ai/ollama-client';
```

2. Create document chunking function (semantic chunking for HR policies):
```typescript
interface DocumentChunk {
  id: string;
  text: string;
  metadata: {
    policyId: string;
    title: string;
    category: string;
    chunkIndex: number;
    totalChunks: number;
  };
}

/**
 * Chunk a policy document for embedding.
 * Uses semantic boundaries (headings, paragraphs) for better RAG retrieval.
 * Target: 256-512 tokens per chunk for fact-focused policy retrieval.
 */
export function chunkDocument(
  policyId: string,
  title: string,
  category: string,
  content: string,
  maxChunkSize: number = 1500 // ~375 tokens
): DocumentChunk[] {
  const chunks: DocumentChunk[] = [];

  // First, split by markdown headers (##, ###)
  const sections = content.split(/\n(?=#{1,3}\s)/);

  for (const section of sections) {
    if (!section.trim()) continue;

    // If section is small enough, keep as single chunk
    if (section.length <= maxChunkSize) {
      chunks.push({
        id: `${policyId}-chunk-${chunks.length}`,
        text: section.trim(),
        metadata: {
          policyId,
          title,
          category,
          chunkIndex: chunks.length,
          totalChunks: 0, // Will be updated after all chunks created
        },
      });
      continue;
    }

    // Split large sections by paragraphs
    const paragraphs = section.split(/\n\n+/);
    let currentChunk = '';

    for (const para of paragraphs) {
      if (currentChunk.length + para.length > maxChunkSize) {
        // Save current chunk
        if (currentChunk.trim()) {
          chunks.push({
            id: `${policyId}-chunk-${chunks.length}`,
            text: currentChunk.trim(),
            metadata: {
              policyId,
              title,
              category,
              chunkIndex: chunks.length,
              totalChunks: 0,
            },
          });
        }
        currentChunk = para;
      } else {
        currentChunk += (currentChunk ? '\n\n' : '') + para;
      }
    }

    // Don't forget last chunk
    if (currentChunk.trim()) {
      chunks.push({
        id: `${policyId}-chunk-${chunks.length}`,
        text: currentChunk.trim(),
        metadata: {
          policyId,
          title,
          category,
          chunkIndex: chunks.length,
          totalChunks: 0,
        },
      });
    }
  }

  // Update totalChunks in all chunks
  for (const chunk of chunks) {
    chunk.metadata.totalChunks = chunks.length;
  }

  return chunks;
}
```

3. Create embedding generation function:
```typescript
/**
 * Generate embedding for a single text using Ollama's nomic-embed-text model.
 * Vector dimension: 768
 */
export async function generateEmbedding(text: string): Promise<number[]> {
  const { embedding } = await embed({
    model: embeddingModel,
    value: text,
  });

  return embedding;
}

/**
 * Generate embeddings for multiple chunks in batch.
 * Processes sequentially to avoid overwhelming Ollama.
 */
export async function generateEmbeddings(
  texts: string[]
): Promise<number[][]> {
  const embeddings: number[][] = [];

  for (const text of texts) {
    const embedding = await generateEmbedding(text);
    embeddings.push(embedding);
  }

  return embeddings;
}
```

4. Export types:
```typescript
export type { DocumentChunk };
```
  </action>
  <verify>
    - `src/lib/qdrant/embeddings.ts` exists
    - Exports `chunkDocument`, `generateEmbedding`, `generateEmbeddings`
    - TypeScript compiles: `pnpm tsc --noEmit`
  </verify>
  <done>
    - Semantic document chunking by headers and paragraphs
    - Embedding generation using Ollama nomic-embed-text
    - Batch embedding support for multiple chunks
    - Chunk metadata includes policy info for retrieval
  </done>
</task>

<task type="auto">
  <name>Task 2: Create semantic search with RBAC filtering</name>
  <files>
    src/lib/qdrant/search.ts
    src/lib/ai/tools/policy-search.ts
  </files>
  <action>
1. Create `src/lib/qdrant/search.ts` for semantic search:

```typescript
import { qdrant, POLICIES_COLLECTION } from './client';
import { generateEmbedding } from './embeddings';

export interface PolicySearchResult {
  content: string;
  title: string;
  category: string;
  score: number;
  policyId: string;
}

/**
 * Search policy documents by semantic similarity.
 * Filters results by user role for RBAC compliance.
 */
export async function searchPolicies(
  query: string,
  userRole: string,
  limit: number = 5,
  minScore: number = 0.5
): Promise<PolicySearchResult[]> {
  // Generate query embedding
  const queryEmbedding = await generateEmbedding(query);

  // Build filter for role-based access
  // visible_to_roles is an array; if empty, visible to all
  const filter = {
    should: [
      // Document has no role restriction (visible to all)
      {
        is_empty: {
          key: 'visible_to_roles',
        },
      },
      // Document is visible to user's role
      {
        key: 'visible_to_roles',
        match: {
          any: [userRole, 'ALL'],
        },
      },
    ],
  };

  // Search Qdrant
  const searchResult = await qdrant.search(POLICIES_COLLECTION, {
    vector: queryEmbedding,
    filter,
    limit,
    with_payload: true,
    score_threshold: minScore,
  });

  // Map results
  return searchResult.map((hit) => ({
    content: (hit.payload?.content as string) || '',
    title: (hit.payload?.title as string) || '',
    category: (hit.payload?.category as string) || '',
    score: hit.score,
    policyId: (hit.payload?.policyId as string) || '',
  }));
}

/**
 * Check if Qdrant collection exists and has documents.
 */
export async function hasPolices(): Promise<boolean> {
  try {
    const info = await qdrant.getCollection(POLICIES_COLLECTION);
    return info.points_count > 0;
  } catch {
    return false;
  }
}
```

2. Create `src/lib/ai/tools/policy-search.ts` for AI tool:

```typescript
import { tool } from 'ai';
import { z } from 'zod';
import { searchPolicies, hasPolices } from '@/lib/qdrant/search';

export interface PolicyToolContext {
  role: string;
}

/**
 * Create AI tool for searching policy documents.
 */
export function createPolicySearchTool(context: PolicyToolContext) {
  return {
    searchPolicies: tool({
      description: `Search company HR policy documents to answer questions about policies, procedures, and guidelines. Use this for questions like "What's the WFH policy?", "How do I claim medical expenses?", "What are the leave rules?". Always cite the source document in your response.`,
      parameters: z.object({
        query: z.string().describe('The question or topic to search for in policy documents'),
      }),
      execute: async ({ query }) => {
        // Check if we have any policies
        const hasDocs = await hasPolices();
        if (!hasDocs) {
          return {
            results: [],
            message: 'No policy documents have been uploaded yet. Please contact HR admin.',
          };
        }

        const results = await searchPolicies(query, context.role);

        if (results.length === 0) {
          return {
            results: [],
            message: `I couldn't find information about "${query}" in our policy documents. Try rephrasing your question or contact HR admin for help.`,
          };
        }

        return {
          results: results.map((r) => ({
            content: r.content,
            source: `${r.title} (${r.category})`,
            relevance: Math.round(r.score * 100) + '%',
          })),
          message: `Found ${results.length} relevant policy sections.`,
        };
      },
    }),
  };
}

export type PolicySearchTools = ReturnType<typeof createPolicySearchTool>;
```
  </action>
  <verify>
    - `src/lib/qdrant/search.ts` exists with `searchPolicies`, `hasPolices`
    - `src/lib/ai/tools/policy-search.ts` exists with `createPolicySearchTool`
    - TypeScript compiles: `pnpm tsc --noEmit`
    - RBAC filter is applied in search (role-based visibility)
  </verify>
  <done>
    - Semantic search using Qdrant vector similarity
    - RBAC filtering by visible_to_roles
    - Minimum score threshold to filter low-relevance results
    - AI tool with clear description for LLM
    - Graceful handling of empty collection
  </done>
</task>

<task type="auto">
  <name>Task 3: Create BullMQ queue and worker for background embedding</name>
  <files>
    src/lib/queues/embedding.queue.ts
    src/lib/queues/workers/embedding.worker.ts
  </files>
  <action>
1. Create `src/lib/queues/embedding.queue.ts`:

```typescript
import { Queue } from 'bullmq';
import { redisConnection } from './connection';

export interface EmbeddingJobData {
  policyId: string;
  title: string;
  category: string;
  content: string;
  visibleToRoles: string[];
}

export const embeddingQueue = new Queue<EmbeddingJobData>('policy-embeddings', {
  connection: redisConnection,
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 5000,
    },
    removeOnComplete: {
      age: 24 * 60 * 60, // 24 hours
    },
    removeOnFail: {
      age: 7 * 24 * 60 * 60, // 7 days
    },
  },
});

/**
 * Add a policy document to the embedding queue.
 * Called when a policy is created or updated.
 */
export async function addEmbeddingJob(data: EmbeddingJobData) {
  const jobId = `embed-${data.policyId}`;

  // Remove any existing job for this policy (handles updates)
  const existingJob = await embeddingQueue.getJob(jobId);
  if (existingJob) {
    await existingJob.remove();
  }

  return embeddingQueue.add('embed-policy', data, {
    jobId,
  });
}

/**
 * Get embedding job status for a policy.
 */
export async function getEmbeddingJobStatus(policyId: string) {
  const jobId = `embed-${policyId}`;
  const job = await embeddingQueue.getJob(jobId);

  if (!job) return null;

  const state = await job.getState();
  return {
    id: job.id,
    state,
    progress: job.progress,
    attemptsMade: job.attemptsMade,
    failedReason: job.failedReason,
  };
}
```

2. Create `src/lib/queues/workers/embedding.worker.ts`:

```typescript
import { Worker, Job } from 'bullmq';
import { redisConnection } from '../connection';
import { qdrant, POLICIES_COLLECTION, ensureCollection } from '@/lib/qdrant/client';
import { chunkDocument, generateEmbedding } from '@/lib/qdrant/embeddings';
import { prisma } from '@/lib/db';
import type { EmbeddingJobData } from '../embedding.queue';

/**
 * Worker that processes policy document embedding jobs.
 * - Chunks the document
 * - Generates embeddings for each chunk
 * - Upserts to Qdrant
 * - Updates PolicyDocument status in Prisma
 */
export const embeddingWorker = new Worker<EmbeddingJobData>(
  'policy-embeddings',
  async (job: Job<EmbeddingJobData>) => {
    const { policyId, title, category, content, visibleToRoles } = job.data;

    console.log(`Processing embedding job for policy: ${title}`);

    try {
      // Update status to processing
      await prisma.policyDocument.update({
        where: { id: policyId },
        data: { embedding_status: 'PROCESSING' },
      });

      // Ensure collection exists
      await ensureCollection();

      // Delete existing chunks for this policy (handles updates)
      await qdrant.delete(POLICIES_COLLECTION, {
        filter: {
          must: [
            { key: 'policyId', match: { value: policyId } },
          ],
        },
      });

      // Chunk the document
      const chunks = chunkDocument(policyId, title, category, content);

      if (chunks.length === 0) {
        throw new Error('Document produced no chunks');
      }

      // Process chunks
      const points = [];
      for (let i = 0; i < chunks.length; i++) {
        const chunk = chunks[i];

        // Update progress
        await job.updateProgress(Math.round((i / chunks.length) * 100));

        // Generate embedding
        const embedding = await generateEmbedding(chunk.text);

        points.push({
          id: chunk.id,
          vector: embedding,
          payload: {
            policyId,
            title,
            category,
            content: chunk.text,
            chunkIndex: chunk.metadata.chunkIndex,
            totalChunks: chunk.metadata.totalChunks,
            visible_to_roles: visibleToRoles,
          },
        });
      }

      // Upsert all points to Qdrant
      await qdrant.upsert(POLICIES_COLLECTION, {
        wait: true,
        points,
      });

      // Update status to completed
      await prisma.policyDocument.update({
        where: { id: policyId },
        data: {
          embedding_status: 'COMPLETED',
          chunk_count: chunks.length,
          last_embedded_at: new Date(),
        },
      });

      console.log(`Completed embedding for policy: ${title} (${chunks.length} chunks)`);

      return { success: true, chunkCount: chunks.length };
    } catch (error) {
      // Update status to failed
      await prisma.policyDocument.update({
        where: { id: policyId },
        data: { embedding_status: 'FAILED' },
      });

      throw error;
    }
  },
  {
    connection: redisConnection,
    concurrency: 1, // Process one at a time to avoid overwhelming Ollama
  }
);

// Event handlers for logging
embeddingWorker.on('completed', (job) => {
  console.log(`Embedding job ${job.id} completed`);
});

embeddingWorker.on('failed', (job, error) => {
  console.error(`Embedding job ${job?.id} failed:`, error.message);
});

// Graceful shutdown
export async function closeEmbeddingWorker() {
  await embeddingWorker.close();
}
```

3. Add worker startup script to package.json (note: don't modify directly, just document the command):

The worker can be started with:
```bash
npx tsx src/lib/queues/workers/embedding.worker.ts
```

Or add to package.json scripts:
```json
"worker:embedding": "npx tsx src/lib/queues/workers/embedding.worker.ts"
```
  </action>
  <verify>
    - `src/lib/queues/embedding.queue.ts` exists with `embeddingQueue`, `addEmbeddingJob`
    - `src/lib/queues/workers/embedding.worker.ts` exists with `embeddingWorker`
    - TypeScript compiles: `pnpm tsc --noEmit`
    - Worker updates PolicyDocument status in Prisma
  </verify>
  <done>
    - BullMQ queue for embedding jobs with retry logic
    - Worker processes documents with progress updates
    - Chunks documents and generates embeddings sequentially
    - Upserts to Qdrant with metadata
    - Updates PolicyDocument status (PENDING -> PROCESSING -> COMPLETED/FAILED)
    - Handles document updates by removing old chunks first
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `pnpm tsc --noEmit`
2. All exports are correct: `grep -r "export" src/lib/qdrant/ src/lib/ai/tools/policy-search.ts`
3. Queue and worker files exist
4. RBAC filter is applied in search (visible_to_roles)
</verification>

<success_criteria>
- Document chunking with semantic boundaries (headers, paragraphs)
- Embedding generation using Ollama nomic-embed-text
- Semantic search with role-based filtering
- AI tool for policy search with clear description
- BullMQ queue and worker for background processing
- PolicyDocument status tracking (PENDING/PROCESSING/COMPLETED/FAILED)
- TypeScript compilation passes
</success_criteria>

<output>
After completion, create `.planning/phases/06-ai-assistant/06-03-SUMMARY.md`
</output>
